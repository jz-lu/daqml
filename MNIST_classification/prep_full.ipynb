{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CQC ML on MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit.quantum_info import Statevector\n",
    "import matplotlib\n",
    "from sklearn.datasets import fetch_openml\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['font.family'] = 'STIXGeneral'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Learning parameters\"\"\"\n",
    "TRAIN_SZ = 10000\n",
    "TEST_SZ = 2000\n",
    "HUGE = False\n",
    "ADD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Import the MNIST dataset\"\"\"\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_number= np.random.permutation(70000)\n",
    "x1, y1 = mnist.data.loc[index_number], mnist.target.loc[index_number]\n",
    "x1.reset_index(drop=True,inplace=True)\n",
    "y1.reset_index(drop=True,inplace=True)\n",
    "y1 = np.array(list(map(int, y1.to_numpy())))\n",
    "\n",
    "# y1_temp = np.zeros((len(y1), 2**4)) * 0.0\n",
    "# for i in range(len(y1)):\n",
    "#     y1_temp[i,y1[i]] = 1.0\n",
    "# y1 = y1_temp\n",
    "\n",
    "# idxs = np.logical_not((y1 == 8) + (y1 == 9))\n",
    "# x1 = x1[idxs]; y1 = y1[idxs]\n",
    "y1_temp = np.zeros((len(y1), 10))\n",
    "for i in range(len(y1)):\n",
    "    y1_temp[i,y1[i]] = 1.0\n",
    "y1 = y1_temp\n",
    "\n",
    "x_train , x_test = x1[:TRAIN_SZ], x1[TRAIN_SZ:TRAIN_SZ+TEST_SZ]\n",
    "y_train , y_test = y1[:TRAIN_SZ], y1[TRAIN_SZ:TRAIN_SZ+TEST_SZ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"What are the dimensions?\"\"\"\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run PCA to reduce the dataset from 784 DOF to, say, 16\"\"\"\n",
    "from sklearn.decomposition import PCA\n",
    "L = 8\n",
    "pca = PCA(n_components=2**L if HUGE else 2*L)\n",
    "reduced_train = pca.fit_transform(x_train)\n",
    "reduced_test = pca.transform(x_test)\n",
    "print(reduced_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save output as a statevector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_to_state(L, vals, add=0):\n",
    "    # np.random.shuffle(vals) # scramble principal components\n",
    "    if HUGE:\n",
    "        vals /= LA.norm(vals)\n",
    "        return Statevector(vals)\n",
    "    else:\n",
    "        thetas = vals[:L] - np.min(vals[:L])\n",
    "        phis = vals[L:] - np.min(vals[L:])\n",
    "        thetas = thetas / np.max(thetas) * np.pi\n",
    "        phis = phis / np.max(phis) * np.pi\n",
    "        states = [Statevector([np.cos(theta/2), np.exp(1j * phi) * np.sin(theta/2)]) for theta, phi in zip(thetas, phis)]\n",
    "        final_state = states[0]\n",
    "        for state in states[1:]:\n",
    "            final_state = final_state.tensor(state)\n",
    "        for _ in range(add):\n",
    "            final_state = final_state.tensor([1,0])\n",
    "        return final_state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1024)\n"
     ]
    }
   ],
   "source": [
    "train_states = np.array([PCA_to_state(L, vals, add=ADD) for vals in reduced_train])\n",
    "test_states = np.array([PCA_to_state(L, vals, add=ADD) for vals in reduced_test])\n",
    "print(train_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "ROOT = \"../../daqml_large_files/MNIST/\"\n",
    "hh = \"\"\n",
    "np.save(f\"{ROOT}/{hh}x_train_full{'_HUGE' if HUGE else ''}.npy\", train_states)\n",
    "np.save(f\"{ROOT}/{hh}y_train_full{'_HUGE' if HUGE else ''}.npy\", y_train)\n",
    "np.save(f\"{ROOT}/{hh}x_test_full{'_HUGE' if HUGE else ''}.npy\", test_states)\n",
    "np.save(f\"{ROOT}/{hh}y_test_full{'_HUGE' if HUGE else ''}.npy\", y_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e79f7a16a78c126de91db62f97abdff470a3bebb0e2f9d2e849142b4fd26e64b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
